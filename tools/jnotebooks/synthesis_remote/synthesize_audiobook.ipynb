{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import re\n",
    "from dataclasses import replace, dataclass\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import banana_dev as banana\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srt import SrtEntry, SrtPair\n",
    "from synthesized_utterance import SynthesizedUtterance\n",
    "from paragraph import Sentence, Paragraph\n",
    "from sample import Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path) -> str:\n",
    "    encodings = ['utf-8', 'utf-16', 'utf-8-sig', 'cp1257', 'iso8859_13',]\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, mode='r', encoding=encoding) as file:\n",
    "                return file.read().strip()\n",
    "        except (NotADirectoryError, FileNotFoundError) as e:\n",
    "            raise Exception(f\"Filepath error {e}\")\n",
    "    raise Exception(\"Could not read file given the encodings\")\n",
    "\n",
    "def get_paragraphs(file_path) -> List[str]:\n",
    "    text = read_txt(file_path)\n",
    "    return [Paragraph(i, text) for i, text in enumerate(re.sub(r\"\\n{2,}\", \"\\n\", text).split('\\n'))]\n",
    "\n",
    "def get_chapters(input_dir: Path) -> dict:\n",
    "    filepaths = [Path(input_dir) / file for file in os.listdir(input_dir)]\n",
    "    return [(filepath.stem, get_paragraphs(filepath)) for filepath in filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraph_to_sentences(paragraph: Paragraph) -> List[str]:      \n",
    "    sentences = []\n",
    "    sentence_idx = 0\n",
    "    \n",
    "    sentence_end_pattern = '[.?!]+[\\'\"]?'\n",
    "    sentence_ends = [e for e in re.finditer(sentence_end_pattern, paragraph.text)]    \n",
    "    if len(sentence_ends) == 0:\n",
    "        # Filter empty\n",
    "        if paragraph.text:\n",
    "            sentences.append(Sentence(0, paragraph.index, paragraph.text))\n",
    "    else:    \n",
    "        i = 0\n",
    "        for idx, e in enumerate(sentence_ends):\n",
    "            text = paragraph.text[i:e.end()]\n",
    "            # Filter empty\n",
    "            if text:\n",
    "                sentences.append(Sentence(idx, paragraph.index, text))\n",
    "            i = e.end() + 1    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_sentences(sentences: List[Sentence], batch_size: int, speed_mult: float):\n",
    "    texts = [sentence.text for sentence in sentences]\n",
    "    outputs = [synthesize(batched_sentences, speed_mult) for batched_sentences in chunked(texts, batch_size)]   \n",
    "    audio_samples = [sf.read(BytesIO(audio))[0] for output in outputs for audio in output]\n",
    "    return [replace(sentence, audio = audio) for sentence, audio in zip(sentences, audio_samples)]\n",
    "\n",
    "def synthesize(sentences: List[str], speed_mult: float):\n",
    "    model_inputs = {'text': sentences, \"speed_multiplier\": speed_mult}\n",
    "    retries, retry_count = 3, 0\n",
    "    while retry_count < retries:\n",
    "        retry_count += 1\n",
    "        try:\n",
    "            out = banana.run(API_KEY, MODEL_KEY, model_inputs)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    if retry_count == retries:\n",
    "        raise Exception(\n",
    "            f\"Retry exceeded retry count of {retry_count}. Max sentence length: {max(len(s) for s in sentences)}.\\n {model_inputs}\"\n",
    "        )\n",
    "\n",
    "    data = out[\"modelOutputs\"][0].get(\"audio\", None)\n",
    "    return [base64.b64decode(audio_bytes) for audio_bytes in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_with_silence(audio0: np.array, audio1: np.array, silence=0.5, sample_rate=22050):\n",
    "    silent_frames = np.array(\n",
    "        AudioSegment.silent(duration=silence * 1000, frame_rate=sample_rate).get_array_of_samples(), \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    return np.concatenate((audio0, silent_frames, audio1))\n",
    "\n",
    "def concatenate_sentences(sentences: List[Sentence], sentence_silence: float, paragraph_silence: float):\n",
    "    audio = sentences[0].audio\n",
    "    paragraph_idx = sentences[0].paragraph_idx\n",
    "    for sentence in sentences[1:]:\n",
    "        if paragraph_idx == sentence.paragraph_idx:\n",
    "            silence = sentence_silence\n",
    "        else:\n",
    "            paragraph_idx = sentence.paragraph_idx\n",
    "            silence = paragraph_silence    \n",
    "        audio = concatenate_with_silence(audio, sentence.audio, silence)\n",
    "    return audio    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(audio: np.array, sample_rate: int, file_path: Path):\n",
    "    os.makedirs(str(file_path.parent), exist_ok=True)\n",
    "    write(str(file_path), SAMPLE_RATE, audio.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def srt_entries_from_sentences(sentences: List[Sentence], fill_sentences: float, fill_paragraphs: float) -> List:\n",
    "    curr_start = 0.0\n",
    "    prev_paragraph = sentences[0].paragraph_idx\n",
    "    srt_entries = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i > 0:\n",
    "            if sentence.paragraph_idx == prev_paragraph:\n",
    "                curr_start += fill_sentences\n",
    "            else:\n",
    "                prev_paragraph = sentence.paragraph_idx\n",
    "                curr_start += fill_paragraphs \n",
    "        \n",
    "        duration = len(sentence.audio) / SAMPLE_RATE\n",
    "        end = curr_start + duration\n",
    "        srt_entries.append(\n",
    "            SrtEntry(idx=i, start=curr_start * 1000, end=end * 1000, text=sentence.text, audio=sentence.audio)\n",
    "        )\n",
    "        curr_start = end\n",
    "    return srt_entries\n",
    "\n",
    "def save_srt_entries_to_file(srt_entries: List[SrtEntry], out_filepath: Path):\n",
    "    text = '\\n\\n'.join([srt_entry.to_string() for srt_entry in srt_entries])\n",
    "    with open(out_filepath, mode='w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SILENCE_BETWEEN_SENTENCES = 1\n",
    "SILENCE_BETWEEN_PARAGRAPHS = 1.7\n",
    "SPEED_MULTIPLIER = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "MODEL_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"\")\n",
    "output_dir = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "chapters = get_chapters(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (name, paragraphs) in enumerate(chapters, start=1):\n",
    "    print(f\"Synthesizing chapter `{name}` ({i}/{len(chapters)})\")\n",
    "\n",
    "    paragraph_sentences = (split_paragraph_to_sentences(paragraph) for paragraph in paragraphs)\n",
    "    sentences = list(sentence for sentences in paragraph_sentences for sentence in sentences)\n",
    "\n",
    "    print(f\"Synthesizing {len(sentences)} sentences\")\n",
    "    synthesized_sentences = synthesize_sentences(sentences, BATCH_SIZE, SPEED_MULTIPLIER)\n",
    "    \n",
    "    chapter_audio = concatenate_sentences(synthesized_sentences, SILENCE_BETWEEN_SENTENCES, SILENCE_BETWEEN_PARAGRAPHS)\n",
    "    save_audio(chapter_audio, SAMPLE_RATE, output_dir / f\"{name}.wav\")\n",
    "    \n",
    "    srt_entries = srt_entries_from_sentences(synthesized_sentences, SILENCE_BETWEEN_SENTENCES, SILENCE_BETWEEN_PARAGRAPHS)\n",
    "    save_srt_entries_to_file(srt_entries, output_dir / f\"{name}.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
