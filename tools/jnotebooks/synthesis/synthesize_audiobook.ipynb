{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from hparams import get_hparams_from_file\n",
    "from src.audio.concat import concat_2d_array_audios_with_silence\n",
    "from src.file import read_book\n",
    "from src.model.checkpoint import load_checkpoint_for_inference\n",
    "from src.model.synthesizer import SynthesizerTrn\n",
    "from src.srt import generate_and_save_audiobook_srt\n",
    "from src.synthesize import synthesize_book\n",
    "from src.text.split import split_book_lines_to_sentences\n",
    "from src.text.symbols import get_vocabulary\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "checkpoint_step = '150000'\n",
    "speaker = 'milda_no_noise_44'\n",
    "# speaker = 'milda_no_noise_44'\n",
    "# checkpoint_step = '1190000'\n",
    "# speaker = 'giedrius_altoriu_sesely'\n",
    "sample_rate = 44100\n",
    "\n",
    "device = 0\n",
    "\n",
    "silence_between_sentences = 0.5  # TODO: [optional? would complicate the generation of srts] pick silence duration from a distribution (e.g. mean - 1.0s, lower bound - 0.5s, upper - 1.5s)\n",
    "silence_between_paragraphs = 1.0\n",
    "\n",
    "book_name = \"Kur_vasara_amžina_stressed\"\n",
    "book_path = f\"/home/aai-labs/inovoice/data/text/audiobooks/{book_name}.txt\"\n",
    "\n",
    "output_dir = f\"/home/aai-labs/inovoice/repos/vits/files/audio/audiobooks/{speaker}/{checkpoint_step}\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "output_filename = f'{book_name}_{speaker}_{checkpoint_step}_{datetime.now().strftime(\"%Y-%d-%m_%H-%M-%S\")}'\n",
    "\n",
    "# checkpoint_filepath = f\"/media/arnas/SSD Disk/inovoice/models/text-to-speech/vits/{speaker}/logs/G_{checkpoint_step}.pth\"\n",
    "checkpoint_filepath = f\"/home/aai-labs/inovoice/models/{speaker}/G_{checkpoint_step}.pth\"\n",
    "\n",
    "hps = get_hparams_from_file(\"/home/aai-labs/inovoice/repos/vits/files/configs/44khz.json\")\n",
    "\n",
    "symbols, _, _ = get_vocabulary(hps.data.language)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-25 22:53:23,972] INFO:PID-8014:MainThread:src.model.checkpoint: Loading checkpoint at /home/aai-labs/inovoice/models/milda_no_noise_44/G_150000.pth\n",
      "[2022-09-25 22:53:24,355] INFO:PID-8014:MainThread:src.model.checkpoint: Loaded checkpoint '/home/aai-labs/inovoice/models/milda_no_noise_44/G_150000.pth'\n"
     ]
    }
   ],
   "source": [
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model).cuda(device)\n",
    "_ = net_g.eval()\n",
    "_ = load_checkpoint_for_inference(checkpoint_filepath, net_g)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "book = read_book(book_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "book_sentences = split_book_lines_to_sentences(book)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "book_sentences = book_sentences[0:25]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00, 11.20it/s]\n"
     ]
    }
   ],
   "source": [
    "audios = synthesize_book(book_sentences, net_g, hps, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "audiobook = concat_2d_array_audios_with_silence(audios,\n",
    "                                                silence_between_dim1=silence_between_sentences,\n",
    "                                                silence_between_dim2=silence_between_paragraphs,\n",
    "                                                sr=hps.data.sample_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "entries = generate_and_save_audiobook_srt(audios, book_sentences, sample_rate, silence_between_sentences,\n",
    "                                          silence_between_paragraphs, Path(f\"{output_dir}/{output_filename}.srt\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "write(f\"{output_dir}/{output_filename}.wav\", sample_rate, audiobook)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
